
# DiagnÃ³stico de DoenÃ§as em Soja com Rede Neural

Este projeto utiliza aprendizado de mÃ¡quina para diagnosticar doenÃ§as em soja com base em um conjunto de dados que contÃ©m vÃ¡rias caracterÃ­sticas relacionadas Ã  planta. A anÃ¡lise Ã© feita com a utilizaÃ§Ã£o de uma rede neural artificial.

## Bibliotecas e Ferramentas Utilizadas

- **Pandas**: Para manipulaÃ§Ã£o e anÃ¡lise de dados.
- **Numpy**: Para operaÃ§Ãµes matemÃ¡ticas e manipulaÃ§Ã£o de arrays.
- **Scikit-learn**: Para prÃ©-processamento de dados, como Label Encoding e One-Hot Encoding, e divisÃ£o de dados em treino e teste.
- **Keras**: Para construir e treinar a rede neural.
- **Matplotlib**: Para visualizaÃ§Ã£o de grÃ¡ficos e mÃ©tricas.

## Passos do Processo

### 1. Leitura do Dataset
O conjunto de dados foi carregado a partir de um arquivo CSV contendo informaÃ§Ãµes sobre soja.

```python
dados = pd.read_csv('soybean.csv')
```

### 2. AnÃ¡lise de Dados
O cÃ³digo realiza a verificaÃ§Ã£o de valores nulos no dataset e calcula a quantidade de classes diferentes presentes no campo 'class'.

```python
null = dados.isnull().sum()
qtd_class = dados['class'].nunique()
```
---

## Objetivo
Construir um modelo preditivo robusto capaz de detectar doenÃ§as em soja a partir de um conjunto de dados clÃ­nicos, com mÃ¡xima precisÃ£o e recall.

---

## Estrutura do Projeto
```
project/
â”‚
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ main.py               # Inicializa o FastAPI e importa o router
â”‚   â”œâ”€â”€ models.py             # Define os dados de entrada com Pydantic
â”‚   â”œâ”€â”€ predict.py            # Realiza a previsÃ£o com o modelo
â”‚   â”œâ”€â”€ preprocess.py         # FunÃ§Ã£o de prÃ©-processamento dos dados
â”‚   â””â”€â”€ router.py             # Define a rota /predict da API
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ diabetes_prediction_dataset.csv  # Dataset original
â”‚   â”œâ”€â”€ dados.py               # Carregamento e manipulaÃ§Ã£o dos dados
â”‚   â”œâ”€â”€ dados_clear.py               # VersÃ£o limpa ou tratada dos dados
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ eda.py                 # AnÃ¡lise exploratÃ³ria de dados
â”‚   â”œâ”€â”€ preprocess.py          # split treino/teste
|   â”œâ”€â”€ preprocess_keras.py    # OneHotEncoder, LabelEncoder, treino/teste
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/            # Treinamento com Modelos Diferentes(model_forest, model_keras, etc ..)
â”‚   â”œâ”€â”€ utils/             # Pasta Metrics e Predicts
|        â”œâ”€â”€ metrics/            # Metricas de todos os modelos (metrics_forest, metrics_keras, etc ..)
â”‚        â””â”€â”€ predict/            # PrediÃ§Ã£o de todos os modelos (predict_forest, predict_keras, etc ..)
â”‚
â”œâ”€â”€ best_model/
â”‚   â”œâ”€â”€ pipeline_soja.pkl  # Melhor modelo serializado
â”‚   â”œâ”€â”€ model.py           # LÃ³gica para escolha e exportaÃ§Ã£o do melhor modelo
|   â”œâ”€â”€ encoder.py         # LÃ³gica para transformaÃ§Ã£o dos dados em LabelEncoders
|   â””â”€â”€ label.encoders.pkl # LÃ³gica de transformaÃ§Ã£o serializado
|
â”œâ”€â”€ dockerfile             # Arquivo com estrutura para subir para o docker
â””â”€â”€ README.md              # DocumentaÃ§Ã£o do projeto
```

---

## Dataset
- VariÃ¡veis de especifacÃµes da planta como tamanho da petala, tipo de planta, tipo de doenÃ§as, etc.
- Sem valores nulos ou inconsistÃªncias encontradas apÃ³s EDA.

---

## Modelagem
- **Melhor modelo usado**: `RandomForest`
- **TÃ©cnicas aplicadas**:
  - Label Encoding (em todas as colunas)
  - Train/test split (60% treino, 40% teste)

---

## ParÃ¢metros do Modelo
```python
RandomForest(
   
)
```

---

## MÃ©tricas de AvaliaÃ§Ã£o
```
RelatÃ³rio de ClassificaÃ§Ã£o:
              precision    recall  f1-score   support

           0       0.98      0.95      0.97     34135
           1       0.96      0.97      0.96     23665
```

- **Excelente performance em ambas as classes**
- **Recall para classe 1 (diabetes)**: 97%
- **F1-Score para classe 1**: 96%

---

## Tecnologias Utilizadas
- Python 3.10+
- XGBoost, RandomForest, SVM, Keras
- Pandas / NumPy
- Scikit-learn
- Seaborn / Matplotlib

---

# API de PrevisÃ£o de DoenÃ§a em Soja com FastAPI

Esta API realiza previsÃµes de doenÃ§as com base em dados de doenÃ§as em soja, utilizando um modelo de machine learning treinado e integrado por meio da biblioteca FastAPI.

## Funcionalidades

- PrevisÃ£o de qual doenÃ§a a soja estÃ¡ sofrendo
- Retorna a probabilidade da previsÃ£o e qual doenÃ§a
- Utiliza modelo de machine learning serializado com `joblib`
- PrÃ©-processamento de dados categÃ³ricos e numÃ©ricos
- Endpoint `POST` disponÃ­vel para consumo por qualquer sistema

## Exemplo de Entrada

```json
{
  "date": "2025-04-24",
  "plant_stand": "normal",
  "precip": "low",
  "temp": "high",
  "hail": "no",
  "crop_hist": "corn",
  "area_damaged": "none",
  "severity": "mild",
  "seed_tmt": "treated",
  "germination": "good",
  "plant_growth": "vigorous",
  "leaves": "healthy",
  "leafspots_halo": "absent",
  "leafspots_marg": "smooth",
  "leafspot_size": "small",
  "leaf_shread": "no",
  "leaf_malf": "none",
  "leaf_mild": "none",
  "stem": "healthy",
  "lodging": "none",
  "stem_cankers": "absent",
  "canker_lesion": "none",
  "fruiting_bodies": "none",
  "external_decay": "none",
  "mycelium": "absent",
  "int_discolor": "none",
  "sclerotia": "absent",
  "fruit_pods": "healthy",
  "fruit_spots": "none",
  "seed": "normal",
  "mold_growth": "none",
  "seed_discolor": "none",
  "seed_size": "normal",
  "shriveling": "none",
  "roots": "healthy"
}

```

---

## Endpoint

### `POST /predict`

**DescriÃ§Ã£o:** Recebe os dados da planta e retorna a probabilidade e o diagnÃ³stico.

### SaÃ­da

```json
{
        "probabilidade": 0.897
        "Resultado": "Tipo de DoenÃ§a :"
        }
```
### Erro

```json
{
  "detail": "Erro interno na previsÃ£o"
}
```

## Inicie o servidor

```bash
uvicorn main:app --reload
```

## Futuras Melhorias
- Teste com outras arquiteturas (Random Forest, Redes Neurais)
- API para servir o modelo via FastAPI ou Flask.
- Alguns ajustes no modelo



# Docker para Projetos Python

Este README fornece os comandos e passos essenciais para rodar e construir um projeto Python utilizando Docker.

## Requisitos

- Docker instalado na sua mÃ¡quina.
- Um projeto Python com todos os arquivos necessÃ¡rios, como `Dockerfile`, `requirements.txt`, etc.

## Passos para usar o Docker

### 1. Criar o arquivo `Dockerfile`

Crie um arquivo chamado `Dockerfile` na raiz do seu projeto. Este arquivo contÃ©m as instruÃ§Ãµes para o Docker construir a imagem do seu projeto. Aqui estÃ¡ um exemplo bÃ¡sico:

```Dockerfile
# Use uma imagem base do Python
FROM python:3.12-slim

# Atualiza os pacotes do sistema e instala dependÃªncias do sistema
RUN apt-get update && apt-get install -y \ 
    gcc \ 
    libffi-dev \ 
    musl-dev \ 
    build-essential \ 
    && rm -rf /var/lib/apt/lists/*

# Instala o setuptools e wheel
RUN pip install --no-cache-dir setuptools wheel

# Copia os arquivos do projeto para o container
COPY . /app

# Define o diretÃ³rio de trabalho dentro do container
WORKDIR /app

# Instala as dependÃªncias do projeto
RUN pip install --no-cache-dir -r requirements.txt

# ExpÃµe a porta que a aplicaÃ§Ã£o usarÃ¡
EXPOSE 8000

# Comando para rodar a API ou aplicaÃ§Ã£o
CMD ["uvicorn", "api.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### 2. Criar o arquivo `requirements.txt`

Crie um arquivo `requirements.txt` com todas as dependÃªncias do seu projeto, por exemplo:

```
fastapi
uvicorn
numpy
pandas
scikit-learn
```

### 3. Construir a Imagem Docker

No terminal, vÃ¡ atÃ© a pasta onde o `Dockerfile` estÃ¡ localizado e execute o seguinte comando para construir a imagem Docker:

```bash
docker build -t nome-da-imagem .
```

### 4. Rodar o Container

Depois de construir a imagem, vocÃª pode rodar um container com o comando:

```bash
docker run -p 8000:8000 nome-da-imagem
```

Isso vai rodar o seu container e expor a aplicaÃ§Ã£o na porta 8000. VocÃª pode acessar a API ou aplicaÃ§Ã£o pelo navegador em `http://localhost:8000`.

### 5. Parar o Container

Para parar o container, use o seguinte comando:

```bash
docker stop nome-do-container
```

Onde `nome-do-container` Ã© o nome ou ID do seu container (vocÃª pode pegar o ID com `docker ps`).

### 6. Remover a Imagem

Se vocÃª quiser remover a imagem apÃ³s o uso, execute:

```bash
docker rmi nome-da-imagem
```

---

Esse Ã© um exemplo bÃ¡sico de como configurar e rodar seu projeto Python no Docker. VocÃª pode personalizar os comandos conforme a necessidade do seu projeto!




# Projeto com Docker Compose para API e MLflow

Este projeto utiliza o **Docker Compose** para rodar uma **API** de previsÃ£o de diabetes e o **MLflow** para o gerenciamento de experimentos e mÃ©tricas do modelo de Machine Learning.

## Estrutura do Projeto

- **api**: ContÃ©m a API criada com **FastAPI** para previsÃ£o de diabetes.
- **mlflow**: Executa o servidor **MLflow** para rastrear e visualizar mÃ©tricas de treinamento de modelos.

## Docker Compose

O **Docker Compose** Ã© utilizado para orquestrar os containers da **API** e do **MLflow**, permitindo que ambos sejam executados em conjunto em um ambiente controlado.

## Como Rodar o Projeto

### Requisitos

- **Docker** instalado
- **Docker Compose** instalado

### Passos para Rodar

1. Clone o repositÃ³rio:

```bash
git clone <URL_DO_REPOSITORIO>
cd <NOME_DO_REPOSITORIO>
```

2. Certifique-se de que vocÃª tem o arquivo **Dockerfile** e o **docker-compose.yml** na raiz do projeto.

3. Para rodar os containers com o Docker Compose, use o seguinte comando:

```bash
docker-compose up --build
```

- O comando `--build` garante que os containers serÃ£o construÃ­dos antes de serem executados.
- O **FastAPI** serÃ¡ acessÃ­vel na porta `8000`.
- O **MLflow** serÃ¡ acessÃ­vel na porta `5000`.

### O que Acontece Durante o Processo

- O **Docker Compose** irÃ¡ criar e iniciar dois serviÃ§os:
  - **api**: A API FastAPI que faz previsÃµes de diabetes. Ela depende do serviÃ§o **mlflow**.
  - **mlflow**: O servidor MLflow que irÃ¡ rastrear e exibir as mÃ©tricas dos experimentos.

### Acessos

- **API**: A API FastAPI estarÃ¡ disponÃ­vel em `http://localhost:8000`.
- **MLflow**: O servidor MLflow estarÃ¡ disponÃ­vel em `http://localhost:5000`.

### Parar os Containers

Para parar e remover os containers em execuÃ§Ã£o, use o comando:

```bash
docker-compose down
```

Isso irÃ¡ parar os serviÃ§os e limpar os containers, redes e volumes associados.


### Para rodar os containers novamente, basta usar o comando:

```bash
docker-compose up
```




# Publicando a Imagem Docker no Docker Hub

Este passo a passo mostra como vocÃª pode **autenticar, taguear e enviar sua imagem Docker para o Docker Hub**, deixando ela pronta para ser usada em ambientes como o Azure App Service.

---

## Verificando suas imagens locais

Antes de taguear ou enviar qualquer imagem, veja quais imagens jÃ¡ estÃ£o disponÃ­veis localmente:

```bash
docker image 
```

ğŸ“Œ Esse comando mostra uma lista com o **REPOSITORY** (nome), **TAG** e **IMAGE ID** das imagens que vocÃª criou ou puxou.

---

## 1. AutenticaÃ§Ã£o no Docker Hub

Antes de publicar a imagem, vocÃª precisa estar autenticado no Docker Hub.

```bash
docker login
```

ğŸ”¸ Esse comando solicitarÃ¡ seu **nome de usuÃ¡rio** e **senha do Docker Hub**.  
ğŸ”¸ ApÃ³s o login bem-sucedido, vocÃª poderÃ¡ interagir com seu repositÃ³rio remoto (push/pull).

---

## 2. Taguear sua imagem local

Vamos dar um "rÃ³tulo" (tag) Ã  imagem local para que ela aponte para o seu repositÃ³rio no Docker Hub. O formato Ã©:

```bash
docker tag <nome_local> <usuario_dockerhub>/<nome_imagem>:<tag>
```

Exemplo:

```bash
docker tag diabetes-api username/diabetes-api:latest
```

Aqui, `diabetes-api` Ã© o nome da sua imagem local,  
`username` Ã© seu usuÃ¡rio no Docker Hub,  
`latest` Ã© a tag (versÃ£o da imagem â€” pode ser `v1`, `prod`, etc).

---

## 3. Enviando (push) a imagem para o Docker Hub

Com a imagem corretamente tagueada, execute:

```bash
docker push mateusgab/diabetes-api:latest
```

Isso enviarÃ¡ sua imagem para o repositÃ³rio `username/diabetes-api` no Docker Hub.

ApÃ³s o push ser concluÃ­do, sua imagem estarÃ¡ disponÃ­vel publicamente (ou privada, se configurado assim) no seu repositÃ³rio.