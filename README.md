
# Diagn√≥stico de Doen√ßas em Soja com Rede Neural

Este projeto utiliza aprendizado de m√°quina para diagnosticar doen√ßas em soja com base em um conjunto de dados que cont√©m v√°rias caracter√≠sticas relacionadas √† planta. A an√°lise √© feita com a utiliza√ß√£o de uma rede neural artificial.

## Bibliotecas e Ferramentas Utilizadas

- **Pandas**: Para manipula√ß√£o e an√°lise de dados.
- **Numpy**: Para opera√ß√µes matem√°ticas e manipula√ß√£o de arrays.
- **Scikit-learn**: Para pr√©-processamento de dados, como Label Encoding e One-Hot Encoding, e divis√£o de dados em treino e teste.
- **Keras**: Para construir e treinar a rede neural.
- **Matplotlib**: Para visualiza√ß√£o de gr√°ficos e m√©tricas.

## Passos do Processo

### 1. Leitura do Dataset
O conjunto de dados foi carregado a partir de um arquivo CSV contendo informa√ß√µes sobre soja.

```python
dados = pd.read_csv('soybean.csv')
```

### 2. An√°lise de Dados
O c√≥digo realiza a verifica√ß√£o de valores nulos no dataset e calcula a quantidade de classes diferentes presentes no campo 'class'.

```python
null = dados.isnull().sum()
qtd_class = dados['class'].nunique()
```

### 3. Pr√©-processamento dos Dados
- **One-Hot Encoding**: A vari√°vel 'previsores' foi transformada em uma representa√ß√£o bin√°ria utilizando o OneHotEncoder.
- **Label Encoding**: A coluna 'classe' foi transformada em valores inteiros, seguidos de uma codifica√ß√£o One-Hot.
- **Padroniza√ß√£o**: Os dados foram normalizados com o uso do `StandardScaler` para garantir que as vari√°veis tenham a mesma escala.

```python
previsores_encoder  = onehotencoder.fit_transform(previsores)
classe_encoded = labelencoder.fit_transform(classe)
classe_encoded = to_categorical(classe_encoded, num_classes=qtd_class)
```

### 4. Divis√£o de Dados
Os dados foram divididos entre treinamento e teste (70% para treinamento e 30% para teste).

```python
x_treinamento, x_teste, y_treinamento, y_teste = train_test_split(previsores_encoder, classe_encoded, test_size=0.3, random_state=0)
```

### 5. Constru√ß√£o do Modelo de Rede Neural
A rede neural foi criada com camadas totalmente conectadas. Utilizou-se a fun√ß√£o de ativa√ß√£o ReLU para as camadas ocultas e Softmax na camada de sa√≠da, devido √† natureza do problema de classifica√ß√£o multiclasse.

```python
classifier = Sequential()
classifier.add(Dense(units=64, kernel_initializer='uniform', activation='relu', input_dim= previsores_encoder.shape[1]))
classifier.add(Dense(units=64, kernel_initializer='uniform', activation='relu'))
classifier.add(Dense(units=qtd_class, kernel_initializer='uniform', activation='softmax'))
```

### 6. Treinamento e Valida√ß√£o
O modelo foi treinado utilizando o algoritmo Adam, com a fun√ß√£o de perda `categorical_crossentropy` (ideal para problemas de classifica√ß√£o multiclasse).

```python
classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
classifier.fit(x_treinamento, y_treinamento, epochs=1000, validation_data=(x_teste, y_teste))
```

### 7. Previs√£o e Avalia√ß√£o
O modelo fez previs√µes sobre os dados de teste, e a matriz de confus√£o foi gerada para avaliar o desempenho do modelo.

```python
previsoes = classifier.predict(x_teste)
confusao = confusion_matrix(np.argmax(y_teste,axis=1),previsoes)
```

## Resultado

O modelo alcan√ßou uma acur√°cia muito alta no conjunto de teste, demonstrando ser eficaz na classifica√ß√£o das doen√ßas em soja.



# Detec√ß√£o de Diabetes com XGBoost

Projeto de classifica√ß√£o para previs√£o de casos de diabetes com uso de Machine Learning. Utilizamos o modelo **XGBoostClassifier**, com t√©cnicas de balanceamento de classes e an√°lise explorat√≥ria de dados (EDA).

---

## Objetivo
Construir um modelo preditivo robusto capaz de detectar casos de diabetes a partir de um conjunto de dados cl√≠nicos, com m√°xima precis√£o e recall, especialmente para a classe minorit√°ria (pacientes com diabetes).

---

## Estrutura do Projeto
```
project/
‚îÇ
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îú‚îÄ‚îÄ main.py               # Inicializa o FastAPI e importa o router
‚îÇ   ‚îú‚îÄ‚îÄ models.py             # Define os dados de entrada com Pydantic
‚îÇ   ‚îú‚îÄ‚îÄ predict.py            # Realiza a previs√£o com o modelo
‚îÇ   ‚îú‚îÄ‚îÄ preprocess.py         # Fun√ß√£o de pr√©-processamento dos dados
‚îÇ   ‚îî‚îÄ‚îÄ router.py             # Define a rota /predict da API
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ diabetes_prediction_dataset.csv  # Dataset original
‚îÇ   ‚îú‚îÄ‚îÄ dados.py               # Carregamento e manipula√ß√£o dos dados
‚îÇ   ‚îú‚îÄ‚îÄ limpo.py               # Vers√£o limpa ou tratada dos dados
‚îÇ
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ eda.py                 # An√°lise explorat√≥ria de dados
‚îÇ   ‚îî‚îÄ‚îÄ preprocessamento.py    # Balanceamento com SMOTE + undersampling, split treino/teste
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ model_training.py      # Treinamento com XGBoost
‚îÇ   ‚îú‚îÄ‚îÄ model_evaluation.py    # Avalia√ß√£o do modelo (classification_report, matriz de confus√£o)
‚îÇ   ‚îî‚îÄ‚îÄ predict.py             # Predi√ß√£o e convers√£o de probabilidades em classes
‚îÇ
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ pipeline_diabetes.pkl  # Modelo final serializado
‚îÇ   ‚îî‚îÄ‚îÄ best_model.py          # L√≥gica para escolha e exporta√ß√£o do melhor modelo
‚îÇ
‚îî‚îÄ‚îÄ README.md                  # Documenta√ß√£o do projeto
```

---

## Dataset
- Vari√°veis de especifac√µes da planta como tamanho da petala, tipo de planta, tipo de doen√ßas, etc.
- Sem valores nulos ou inconsist√™ncias encontradas ap√≥s EDA.

---

## Modelagem
- **Melhor modelo usado**: `RandomForest`
- **T√©cnicas aplicadas**:
  - Label Encoding (em todas as colunas)
  - Train/test split (60% treino, 40% teste)

---

## Par√¢metros do Modelo
```python
RandomForest(
   
)
```

---

## M√©tricas de Avalia√ß√£o
```
Relat√≥rio de Classifica√ß√£o:
              precision    recall  f1-score   support

           0       0.98      0.95      0.97     34135
           1       0.96      0.97      0.96     23665
```

- **Excelente performance em ambas as classes**
- **Recall para classe 1 (diabetes)**: 97%
- **F1-Score para classe 1**: 96%

---

## Tecnologias Utilizadas
- Python 3.10+
- XGBoost, RandomForest, SVM, Keras
- Pandas / NumPy
- Scikit-learn
- Seaborn / Matplotlib

---

# API de Previs√£o de Diabetes com FastAPI

Esta API realiza previs√µes de doen√ßas com base em dados de doen√ßas em soja, utilizando um modelo de machine learning treinado e integrado por meio da biblioteca FastAPI.

## Funcionalidades

- Previs√£o se um paciente tem diabetes ou n√£o
- Retorna a probabilidade da previs√£o
- Utiliza modelo de machine learning serializado com `joblib`
- Pr√©-processamento de dados categ√≥ricos e num√©ricos
- Endpoint `POST` dispon√≠vel para consumo por qualquer sistema

## Exemplo de Entrada

```json
{
  "gender": "Male",
  "age": 45,
  "hypertension": 1,
  "heart_disease": 0,
  "smoking_history": "former",
  "bmi": 28.7,
  "HbA1c_level": 6.5,
  "blood_glucose_level": 140
}
```

---

## Endpoint

### `POST /predict`

**Descri√ß√£o:** Recebe os dados do paciente e retorna a probabilidade e o diagn√≥stico.

### Sa√≠da

```json
{
  "probabilidade": 0.823,
  "diabetico": "Diabetico"
}
```
### Erro

```json
{
  "detail": "Erro interno na previs√£o"
}
```

## Inicie o servidor

```bash
uvicorn main:app --reload
```

## Futuras Melhorias
- Teste com outras arquiteturas (Random Forest, Redes Neurais)
- API para servir o modelo via FastAPI ou Flask.
- Alguns ajustes no modelo



# Docker para Projetos Python

Este README fornece os comandos e passos essenciais para rodar e construir um projeto Python utilizando Docker.

## Requisitos

- Docker instalado na sua m√°quina.
- Um projeto Python com todos os arquivos necess√°rios, como `Dockerfile`, `requirements.txt`, etc.

## Passos para usar o Docker

### 1. Criar o arquivo `Dockerfile`

Crie um arquivo chamado `Dockerfile` na raiz do seu projeto. Este arquivo cont√©m as instru√ß√µes para o Docker construir a imagem do seu projeto. Aqui est√° um exemplo b√°sico:

```Dockerfile
# Use uma imagem base do Python
FROM python:3.12-slim

# Atualiza os pacotes do sistema e instala depend√™ncias do sistema
RUN apt-get update && apt-get install -y \ 
    gcc \ 
    libffi-dev \ 
    musl-dev \ 
    build-essential \ 
    && rm -rf /var/lib/apt/lists/*

# Instala o setuptools e wheel
RUN pip install --no-cache-dir setuptools wheel

# Copia os arquivos do projeto para o container
COPY . /app

# Define o diret√≥rio de trabalho dentro do container
WORKDIR /app

# Instala as depend√™ncias do projeto
RUN pip install --no-cache-dir -r requirements.txt

# Exp√µe a porta que a aplica√ß√£o usar√°
EXPOSE 8000

# Comando para rodar a API ou aplica√ß√£o
CMD ["uvicorn", "api.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### 2. Criar o arquivo `requirements.txt`

Crie um arquivo `requirements.txt` com todas as depend√™ncias do seu projeto, por exemplo:

```
fastapi
uvicorn
numpy
pandas
scikit-learn
```

### 3. Construir a Imagem Docker

No terminal, v√° at√© a pasta onde o `Dockerfile` est√° localizado e execute o seguinte comando para construir a imagem Docker:

```bash
docker build -t nome-da-imagem .
```

### 4. Rodar o Container

Depois de construir a imagem, voc√™ pode rodar um container com o comando:

```bash
docker run -p 8000:8000 nome-da-imagem
```

Isso vai rodar o seu container e expor a aplica√ß√£o na porta 8000. Voc√™ pode acessar a API ou aplica√ß√£o pelo navegador em `http://localhost:8000`.

### 5. Parar o Container

Para parar o container, use o seguinte comando:

```bash
docker stop nome-do-container
```

Onde `nome-do-container` √© o nome ou ID do seu container (voc√™ pode pegar o ID com `docker ps`).

### 6. Remover a Imagem

Se voc√™ quiser remover a imagem ap√≥s o uso, execute:

```bash
docker rmi nome-da-imagem
```

---

Esse √© um exemplo b√°sico de como configurar e rodar seu projeto Python no Docker. Voc√™ pode personalizar os comandos conforme a necessidade do seu projeto!




# Projeto com Docker Compose para API e MLflow

Este projeto utiliza o **Docker Compose** para rodar uma **API** de previs√£o de diabetes e o **MLflow** para o gerenciamento de experimentos e m√©tricas do modelo de Machine Learning.

## Estrutura do Projeto

- **api**: Cont√©m a API criada com **FastAPI** para previs√£o de diabetes.
- **mlflow**: Executa o servidor **MLflow** para rastrear e visualizar m√©tricas de treinamento de modelos.

## Docker Compose

O **Docker Compose** √© utilizado para orquestrar os containers da **API** e do **MLflow**, permitindo que ambos sejam executados em conjunto em um ambiente controlado.

## Como Rodar o Projeto

### Requisitos

- **Docker** instalado
- **Docker Compose** instalado

### Passos para Rodar

1. Clone o reposit√≥rio:

```bash
git clone <URL_DO_REPOSITORIO>
cd <NOME_DO_REPOSITORIO>
```

2. Certifique-se de que voc√™ tem o arquivo **Dockerfile** e o **docker-compose.yml** na raiz do projeto.

3. Para rodar os containers com o Docker Compose, use o seguinte comando:

```bash
docker-compose up --build
```

- O comando `--build` garante que os containers ser√£o constru√≠dos antes de serem executados.
- O **FastAPI** ser√° acess√≠vel na porta `8000`.
- O **MLflow** ser√° acess√≠vel na porta `5000`.

### O que Acontece Durante o Processo

- O **Docker Compose** ir√° criar e iniciar dois servi√ßos:
  - **api**: A API FastAPI que faz previs√µes de diabetes. Ela depende do servi√ßo **mlflow**.
  - **mlflow**: O servidor MLflow que ir√° rastrear e exibir as m√©tricas dos experimentos.

### Acessos

- **API**: A API FastAPI estar√° dispon√≠vel em `http://localhost:8000`.
- **MLflow**: O servidor MLflow estar√° dispon√≠vel em `http://localhost:5000`.

### Parar os Containers

Para parar e remover os containers em execu√ß√£o, use o comando:

```bash
docker-compose down
```

Isso ir√° parar os servi√ßos e limpar os containers, redes e volumes associados.


### Para rodar os containers novamente, basta usar o comando:

```bash
docker-compose up
```




# Publicando a Imagem Docker no Docker Hub

Este passo a passo mostra como voc√™ pode **autenticar, taguear e enviar sua imagem Docker para o Docker Hub**, deixando ela pronta para ser usada em ambientes como o Azure App Service.

---

## Verificando suas imagens locais

Antes de taguear ou enviar qualquer imagem, veja quais imagens j√° est√£o dispon√≠veis localmente:

```bash
docker image 
```

üìå Esse comando mostra uma lista com o **REPOSITORY** (nome), **TAG** e **IMAGE ID** das imagens que voc√™ criou ou puxou.

---

## 1. Autentica√ß√£o no Docker Hub

Antes de publicar a imagem, voc√™ precisa estar autenticado no Docker Hub.

```bash
docker login
```

üî∏ Esse comando solicitar√° seu **nome de usu√°rio** e **senha do Docker Hub**.  
üî∏ Ap√≥s o login bem-sucedido, voc√™ poder√° interagir com seu reposit√≥rio remoto (push/pull).

---

## 2. Taguear sua imagem local

Vamos dar um "r√≥tulo" (tag) √† imagem local para que ela aponte para o seu reposit√≥rio no Docker Hub. O formato √©:

```bash
docker tag <nome_local> <usuario_dockerhub>/<nome_imagem>:<tag>
```

Exemplo:

```bash
docker tag diabetes-api username/diabetes-api:latest
```

Aqui, `diabetes-api` √© o nome da sua imagem local,  
`username` √© seu usu√°rio no Docker Hub,  
`latest` √© a tag (vers√£o da imagem ‚Äî pode ser `v1`, `prod`, etc).

---

## 3. Enviando (push) a imagem para o Docker Hub

Com a imagem corretamente tagueada, execute:

```bash
docker push mateusgab/diabetes-api:latest
```

Isso enviar√° sua imagem para o reposit√≥rio `username/diabetes-api` no Docker Hub.

Ap√≥s o push ser conclu√≠do, sua imagem estar√° dispon√≠vel publicamente (ou privada, se configurado assim) no seu reposit√≥rio.